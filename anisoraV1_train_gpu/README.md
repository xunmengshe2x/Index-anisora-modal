## ðŸš€ Quick Start

### 1. Environment Set Up

```bash
cd anisoraV1_train_gpu
conda create -n anisoraV1_gpu python=3.10
conda activate anisoraV1_gpu
pip install -r requirements.txt
```

## 2. Download Pretrained Models:

Please download the text_encoder and vae from [HuggingFace](https://huggingface.co/IndexTeam/Index-anisora/tree/main/CogVideoX_VAE_T5) or [ModelScope](https://modelscope.cn/models/bilibili-index/Index-anisora/files) and put them in `./sat/5b_tool_models/`. 

## 3. Prepare Training Data:

Please construct the json file for your dataset following the format of [data.json](./sat/demo_data/data.json). 
For VAE feature extraction, please refer to the [cli_vae_demo.py](https://github.com/THUDM/CogVideo/blob/main/inference/cli_vae_demo.py) in official CogVideoX repository.


## 4. Training

```bash
bash ./script/gpu_run.sh
```


